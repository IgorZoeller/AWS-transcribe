 I think it's worth spending some time learning about the different kinds of processors that are available, at least on AWS. So AWS underlying instances can have access to a variety of different processors to meet specific cloud workload needs. This is going to be really determined based on the instance family and its version. But let's just make sure we're familiar with these brands. The first is Intel Xeon processors. These are similar to your Intel desktop CPUs or your laptops, but they have advanced capabilities that make them much more performant for doing non desktop things, which is basically what we're generally doing in the cloud. There is another line called Intel Xeon scalable, which is a better performing version of the Intel Xeon processor. But you know, I'm not going to distinguish that there. Then we have AMD is EP y c. I have no idea what EP y c stands for. I just know that it's an alternative to Intel's Intel based instances. And the idea here is that you will see instances where it will indicate that there is a family or sorry, a processor version of let's say, I don't know, like maybe there's one for t fours or t threes. And they have one for AMD. And the idea is that it's basically the same thing as using the Intel one, but it's going to be more cost effective because AMD is whole thing is to try to undercut Intel, then you have Nvidia GPUs, these are in grass, graphic intensive workloads often used for machine learning. So at one point, you could attach GPUs. I think they got rid of that service or I forgot what it was called. But anyway, it was something that they had and they got kind of rid of so. But anyway, the idea is that you can spin up instance types that will have GPU permanently attached to it, but not necessarily attach a bunch of them. We have a Miss graviton processors, this is a custom built processor by AWS specifically for the arm architecture. And arm is really good in any case that you can run x86, you can pretty much run arm and your software should generally work with no issues. And it's just going to be more efficient. And it usually is more cost effective. So when you have that opportunity, use the arm architecture when you can, then you have Intel, habanah gaudy processors. So Intel acquired habanah, which made this very specialized processor for machine learning called Gotti. There's like a bunch of versions of them just like graviton has version one, two and three Gotti is like, I think on version four or something now. And it is a very powerful processor for machine learning. You have Intel FPGA. So FPGA stands for fuel programmable, programmable gate arrays, for workloads that benefit from custom hardware acceleration. I don't know much about this space, but it sounds like a programmable processor, which sounds very powerful. Then you have, I don't know how to pronounce it, but I'm gonna try Zill Zill nix, zillings zillings. And basically, this is just like Intel FPGA, but it's AMD version of it, I think AMD acquired this company. So there's that, then there are a couple of specialized processors made by AWS, specifically for machine learning, the infer, Ntia, which is specifically for ml inference, and then you have trit training, which is specifically for training models. So there's specialized chips, specifically for inference and machine learning. But yeah, there you go.