 Let's take a look at some bucket restrictions limitations. This is not the exhaustive list, as we will cover that later in the cheat sheets. But for now, I just want to get some top level information to you. So you can remember this as we're working through the labs and the lectures here. The first is that you can create up to 100 buckets within your AWS account. If you need more, you can open a service request limit to 1000 buckets, it's pretty easy to manage 100 buckets. I've, I've definitely filled out 100 buckets before, but mostly it's because there's a lot of applications that can randomly generate bucket names for you. And you might have a bunch of junk buckets, so you just have to better manage it. Often you do not need more than 100 buckets, you need to empty a bucket first before you can delete it, this will be something you will see again and again and again, and in labs, that will have to empty your buckets or make note of that there is no max bucket size. And there is no limit to the number of objects in a bucket. There are limitations based on some things. So for instance, files can be between zero and five terabytes, I want to make an emphasis that you can have a zero byte file. And you can have a file as large as five terabytes. Have I ever attempted to upload a five terabyte file? No, but the documentation says that you can do it. files that are larger than 100 megabytes. It was recommends to use multi part upload, which we definitely show in this course. And the CLI does make it pretty easy to do. For s3. For AWS outposts, it has limits. We'll talk about that in the outpost section, which is separate from s3, where we talk about all all of the output services and the differences there. But the idea is that outposts allows you to run a rack of servers, which is AWS hardware loaded with AWS software, and it has the S3 service loaded onto it. And so it just cannot do the exact same thing as the cloud version of it. But it's still very powerful to have if you can afford it. AWS says in the documentation that forget put, listen, delete operations, they're designed to be highly available. But for create, delete and configuration option operations, you should run them less. It's odd that they would say that this is highly available for the delete, but don't run the delete very often. But I guess the idea is that, you know, they're talking about high frequency of configuration changes or high frequency of these things. So you know, if it's reads, reads or updates, totally fine. If it's these other things, then you know, you might run into issues. But again, I've never had issues, but it depends at what scale you're working at. But the things I want to take away from this is 100 buckets 1000 buckets, you got to empty that bucket first. There's no max bucket size and no limit on the number of objects. It's good to remember this as well zero to five terabytes that definitely shows up on the exam. They love to hit you with that one there. But there you go. Okay, ciao.